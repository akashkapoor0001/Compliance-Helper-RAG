# ğŸ¤– Compliance Helper RAG System  
### *AI-powered Compliance & Policy Question Answering using Groq LLaMA + Local Embeddings*

---

## ğŸ“Œ Overview  

**Compliance Helper RAG** is a high-performance Retrieval-Augmented Generation (RAG) application designed to answer compliance and policy-related questions directly from uploaded documents.

This project utilizes:

- âš¡ **Groq LLaMA 3.1** (ultra-fast, deterministic policy Q&A)  
- ğŸ” **HuggingFace MiniLM embeddings** (local, free, secure)  
- ğŸ“š **FAISS vector search** (high-speed semantic retrieval)  
- ğŸ–¥ï¸ **Streamlit interface** (smooth, user-friendly UI)

The assistant answers **only from uploaded documents** and provides clean, structured citations like: [Terms of Service Twitter.pdf#28]

---

## ğŸš€ Key Features  

### âœ” Upload PDF/TXT policies  
Supports internal documents, legal terms, compliance manuals, guidelines, and more.

### âœ” Fast ingestion + optimized chunking  
Chunking tailored for legal/policy content ensures high-quality retrieval.

### âœ” Local embeddings (no API cost)  
Uses `sentence-transformers/all-MiniLM-L6-v2`, giving:

- High semantic quality  
- Zero rate limits  
- Full data privacy  

### âœ” Groq-accelerated LLaMA 3.1 for Q&A  
Super fast reasoning using:

- `llama-3.1-8b-instant` (default)
- or upgrade to `llama-3.1-70b-versatile`

### âœ” Hybrid retrieval (semantic + lexical)  
Improves accuracy for compliance/legal queries:

- Minimum age requirements  
- Rights and restrictions  
- Data usage rules  
- Allowed vs. prohibited actions  

### âœ” Clean structured citations  
The assistant:

- âŒ Never hallucinates citations  
- ğŸ“Œ Only cites the chunks used  
- ğŸ“ Includes max 1â€“2 citations  
- ğŸ“ Formats citations consistently  

---

## ğŸ—ï¸ Architecture  

```bash
                                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                       â”‚   Uploaded PDFs    â”‚
                                                       â”‚       /TXT         â”‚
                                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                                  â–¼
                                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                   â”‚   Ingestion(Chunk + Embed)â”‚
                                                   â”‚  - HF MiniLM Embeddings   â”‚
                                                   â”‚  - FAISS Vector Index     â”‚
                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                              â–¼
                                                  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                  â”‚      Hybrid Retriever       â”‚
                                                  â”‚ (semantic + lexical rerank) â”‚
                                                  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                             â–¼
                                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                   â”‚       System Prompt      â”‚
                                                   â”‚ (strict citation control)â”‚
                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                              â–¼
                                                   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                   â”‚     Groq LLaMA 3.1 LLM   â”‚
                                                   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                                                              â–¼
                                                       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                                                       â”‚    Final Answer    â”‚
                                                       â”‚  + Clean Citations â”‚
                                                       â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```   

---

## âš™ï¸ Installation  

### 1ï¸âƒ£ Clone the repository  
```bash
git clone https://github.com/akashkapoor0001/Compliance-Helper-RAG.git
cd Compliance-Helper-RAG
```
### 2ï¸âƒ£ Create a virtual environment
```bash
python -m venv .venv
.venv/Scripts/activate
```
### 3ï¸âƒ£ Install dependencies
```bash
pip install -r requirements.txt
```
### 4ï¸âƒ£ Create a .env file
```bash
âš ï¸ Never push .env to GitHub

# .env.example
GROQ_API_KEY=YOUR_GROQ_API_KEY
LLM_MODEL=YOUR_LLM_MODEL
EMBEDDING_MODEL=YOUR_EMBEDDING_MODEL
VECTOR_STORE_PATH=data/faiss.index
METADATA_PATH=data/metadata.json
CHUNK_SIZE=1200
CHUNK_OVERLAP=200
MAX_RETRIEVALS=8
ALLOW_WEB_FALLBACK=False
```

## ğŸ“¥ Usage

### Run the Streamlit app
```bash
streamlit run app.py
```

In the UI, you can:
```bash
ğŸ“„ Upload policy documents

âš™ï¸ Build semantic index

â“ Ask compliance questions

ğŸ“Œ See citations for every answer
```

## ğŸ“ Repository Structure
```bash
Compliance-Helper-RAG/
â”‚
â”œâ”€â”€ app.py
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .gitignore
â”œâ”€â”€ .env
â”‚
â”œâ”€â”€ config/
â”‚   â””â”€â”€ config.py
â”‚
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ embeddings.py
â”‚   â””â”€â”€ llm.py
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ ingest.py
â”‚   â”œâ”€â”€ retriever.py
â”‚   â””â”€â”€ response_formatter.py
â”‚
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ reindex_twitter_complete.py
â”‚
â””â”€â”€ data/                     # Ignored by Git
    â”œâ”€â”€ uploaded/             # Uploaded files
    â”œâ”€â”€ faiss.index           # Vector index
    â””â”€â”€ metadata.json         # Chunk metadata

```
## ğŸ›¡ï¸ Security
```bash
.env is ignored via .gitignore

No external API calls for embeddings

Documents never leave your machine

Groq handles only the LLM reasoning

No sensitive metadata is logged
```

## ğŸ§ª Future Improvements
```bash
Add BM25 retriever

Knowledge graph extraction

Conversation memory (multi-turn RAG)

Export Q&A as a compliance report

Admin dashboard for document management

Deployment to Streamlit Cloud / Vercel
```

## ğŸ’¡ Contributing
```bash
Pull requests are welcome!
Please follow PEP8 and include docstrings wherever possible.
```

## ğŸ“œ License
```bash
This project is licensed under the MIT License â€” free for personal and commercial use.
```
